"""
Integration tests for Python client <> Server communication.

These tests verify that spans generated by the Python client are correctly
received and stored by the AIQA server.

Prerequisites:
- AIQA server must be running and accessible
- Set AIQA_SERVER_URL and AIQA_API_KEY environment variables
- Server must have ElasticSearch and PostgreSQL configured
- The API key must be valid and associated with an organisation
"""

import os
import time
import uuid
import pytest
import requests
from typing import Optional, Dict, Any, List
from aiqa import WithTracing, flush_tracing
from aiqa.http_utils import get_server_url, get_api_key, build_headers
from dotenv import load_dotenv

load_dotenv()

# Test configuration
TEST_MARKER_PREFIX = "integration_test_"


def get_test_marker() -> str:
    """Generate a unique test marker for this test run."""
    return f"{TEST_MARKER_PREFIX}{uuid.uuid4().hex[:8]}"


def query_spans(query: str, limit: int = 100) -> Dict[str, Any]:
    """
    Query spans from the server API.
    
    Args:
        query: Search query string (e.g., "name:test_span")
        limit: Maximum number of results
        
    Returns:
        Response dictionary with 'hits' and 'total' fields
    """
    server_url = get_server_url()
    api_key = get_api_key()
    
    url = f"{server_url}/span"
    params = {
        "q": query,
        "limit": str(limit),
        "fields": "*",  # Include all fields including attributes
    }
    
    headers = build_headers(api_key)
    
    # Don't accept compressed responses to avoid parsing issues
    headers['Accept-Encoding'] = 'identity'
    response = requests.get(url, params=params, headers=headers)
    if response.status_code != 200:
        raise ValueError(f"Failed to query spans: {response.status_code} - {response.text[:500]}")
    
    return response.json()


def wait_for_spans(
    query: str,
    expected_count: int = 1,
    max_wait_seconds: int = 10,
    poll_interval: float = 0.5
) -> List[Dict[str, Any]]:
    """
    Wait for spans to appear in the server, with retry logic.
    
    Args:
        query: Search query string
        expected_count: Expected number of spans
        max_wait_seconds: Maximum time to wait
        poll_interval: Time between polls
        
    Returns:
        List of span dictionaries
    """
    start_time = time.time()
    while time.time() - start_time < max_wait_seconds:
        result = query_spans(query)
        hits = result.get("hits", [])
        if len(hits) >= expected_count:
            return hits
        time.sleep(poll_interval)
    
    # Return whatever we have after timeout
    result = query_spans(query)
    return result.get("hits", [])


@pytest.fixture(scope="function")
def test_marker():
    """Fixture that provides a unique test marker for each test."""
    return get_test_marker()


@pytest.fixture(scope="function")
def check_server_available():
    """Fixture that skips tests if server is not available."""
    server_url = os.getenv("AIQA_SERVER_URL")
    api_key = os.getenv("AIQA_API_KEY")
    
    if not server_url or not api_key:
        pytest.skip("AIQA_SERVER_URL and AIQA_API_KEY environment variables must be set")
    
    # Try to connect to server
    # Any HTTP response (even error codes) means the server is up and responding
    # Only connection errors (timeout, DNS failure, etc.) mean the server is down
    try:
        url = f"{server_url.rstrip('/')}/span"
        headers = build_headers(api_key)
        response = requests.get(
            url,
            params={"q": "name:nonexistent", "limit": "1"},
            headers=headers,
            timeout=5
        )
        # Any HTTP response means server is up (even 400, 404, 500, etc.)
        # We got a response, so server is available
    except requests.exceptions.RequestException as e:
        pytest.skip(f"Cannot connect to server: {e}")


@pytest.mark.asyncio
async def test_basic_span_generation_and_retrieval(test_marker, check_server_available):
    """Test that a simple span is generated and can be retrieved from the server."""
    # Create a traced function with a unique name
    @WithTracing(name=f"test_function_{test_marker}")
    def test_function(x: int, y: int) -> int:
        """A simple test function."""
        return x + y
    
    # Call the function to generate a span
    result = test_function(5, 3)
    assert result == 8
    
    # Flush spans to ensure they're sent
    await flush_tracing()
    
    # Wait for span to appear in server
    query = f'name:test_function_{test_marker}'
    hits = wait_for_spans(query, expected_count=1, max_wait_seconds=10)
    
    assert len(hits) >= 1, f"Expected at least 1 span, found {len(hits)}"
    
    # Find our span
    span = hits[0]
    assert span["name"] == f"test_function_{test_marker}"
    assert span.get("status", {}).get("code") == 1  # OK status
    assert "traceId" in span
    assert "spanId" in span
    assert "startTime" in span
    assert "endTime" in span


@pytest.mark.asyncio
async def test_multiple_spans_generation(test_marker, check_server_available):
    """Test that multiple spans are generated and can be retrieved."""
    # Create multiple traced functions
    @WithTracing(name=f"test_func_a_{test_marker}")
    def func_a(x: int) -> int:
        return x * 2
    
    @WithTracing(name=f"test_func_b_{test_marker}")
    def func_b(x: int) -> int:
        return x + 10
    
    @WithTracing(name=f"test_func_c_{test_marker}")
    def func_c(x: int) -> int:
        return x - 5
    
    # Call all functions
    assert func_a(5) == 10
    assert func_b(5) == 15
    assert func_c(5) == 0
    
    # Flush spans
    await flush_tracing()
    
    # Query for all spans with our test marker using OR query
    query = (
        f'name:test_func_a_{test_marker} OR '
        f'name:test_func_b_{test_marker} OR '
        f'name:test_func_c_{test_marker}'
    )
    hits = wait_for_spans(query, expected_count=3, max_wait_seconds=10)
    
    assert len(hits) >= 3, f"Expected at least 3 spans, found {len(hits)}"
    
    # Verify we have all three spans
    span_names = {span["name"] for span in hits if test_marker in span.get("name", "")}
    expected_names = {
        f"test_func_a_{test_marker}",
        f"test_func_b_{test_marker}",
        f"test_func_c_{test_marker}",
    }
    assert expected_names.issubset(span_names), f"Missing spans. Found: {span_names}, Expected: {expected_names}"


@pytest.mark.asyncio
async def test_span_with_attributes(test_marker, check_server_available):
    """Test that spans with attributes are correctly stored and retrieved."""
    # Create a function that will have input/output attributes
    @WithTracing(name=f"test_attrs_{test_marker}")
    def function_with_attrs(data: dict) -> dict:
        """Function with input/output that should be captured as attributes."""
        return {"result": data.get("value", 0) * 2, "processed": True}
    
    # Call with specific input
    input_data = {"value": 42, "test_marker": test_marker}
    output = function_with_attrs(input_data)
    assert output["result"] == 84
    
    # Flush spans
    await flush_tracing()
    
    # Query for our span
    query = f'name:test_attrs_{test_marker}'
    hits = wait_for_spans(query, expected_count=1, max_wait_seconds=10)
    
    assert len(hits) >= 1, f"Expected at least 1 span, found {len(hits)}"
    
    span = hits[0]
    assert span["name"] == f"test_attrs_{test_marker}"
    
    # Verify attributes are present (they may be in attributes or unindexed_attributes)
    attributes = span.get("attributes", {})
    unindexed_attributes = span.get("unindexed_attributes", {})
    all_attrs = {**attributes, **unindexed_attributes}
    
    # Check that input/output are captured (exact structure may vary)
    assert "input" in all_attrs or "output" in all_attrs, "Span should have input or output attributes"


@pytest.mark.asyncio
async def test_span_status_code(test_marker, check_server_available):
    """Test that span status codes are correctly stored."""
    # Create a function that succeeds
    @WithTracing(name=f"test_success_{test_marker}")
    def successful_function() -> str:
        return "success"
    
    # Create a function that raises an exception (should have ERROR status)
    @WithTracing(name=f"test_error_{test_marker}")
    def error_function() -> str:
        raise ValueError("Test error")
    
    # Call successful function
    assert successful_function() == "success"
    
    # Call error function (should raise exception)
    try:
        error_function()
        assert False, "Function should have raised an exception"
    except ValueError:
        pass  # Expected
    
    # Flush spans
    await flush_tracing()
    
    # Query for both spans using OR query
    query = f'name:test_success_{test_marker} OR name:test_error_{test_marker}'
    hits = wait_for_spans(query, expected_count=2, max_wait_seconds=10)
    
    assert len(hits) >= 2, f"Expected at least 2 spans, found {len(hits)}"
    
    # Find the spans
    success_span = next((s for s in hits if s["name"] == f"test_success_{test_marker}"), None)
    error_span = next((s for s in hits if s["name"] == f"test_error_{test_marker}"), None)
    
    assert success_span is not None, "Success span not found"
    assert error_span is not None, "Error span not found"
    
    # Verify status codes
    assert success_span.get("status", {}).get("code") == 1, "Success span should have OK status (1)"
    assert error_span.get("status", {}).get("code") == 2, "Error span should have ERROR status (2)"


@pytest.mark.asyncio
async def test_span_auto_flush_no_explicit_flush(test_marker, check_server_available):
    """
    Test that spans are automatically sent to the server without requiring an explicit flush.
    
    This verifies that the BatchSpanProcessor automatically flushes spans periodically,
    so users don't need to call flush_tracing() in normal operation.
    """
    # Create a traced function with a unique name
    @WithTracing(name=f"test_auto_flush_{test_marker}")
    def test_function(x: int, y: int) -> int:
        """A simple test function that should auto-flush."""
        return x * y
    
    # Call the function to generate a span
    result = test_function(7, 6)
    assert result == 42
    
    # IMPORTANT: Do NOT call flush_tracing() here
    # The span should be automatically sent by BatchSpanProcessor
    
    # Wait for span to appear in server with longer timeout to allow for auto-flush
    # BatchSpanProcessor typically flushes every 5 seconds, so we wait at least 10 seconds
    query = f'name:test_auto_flush_{test_marker}'
    hits = wait_for_spans(query, expected_count=1, max_wait_seconds=15, poll_interval=0.5)
    
    assert len(hits) >= 1, f"Expected at least 1 span to be auto-flushed, found {len(hits)}"
    
    # Find our span
    span = hits[0]
    assert span["name"] == f"test_auto_flush_{test_marker}"
    assert span.get("status", {}).get("code") == 1  # OK status
    assert "traceId" in span
    assert "spanId" in span
    assert "startTime" in span
    assert "endTime" in span

